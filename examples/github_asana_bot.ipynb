{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c2a12b",
   "metadata": {},
   "source": [
    "# Example: evolving a buggy_coder into a github asana syncing bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cf7e8",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "- OPENAI_API_KEY\n",
    "- E2B_API_KEY\n",
    "- COMPOSIO_API_KEY\n",
    "- ASANA_WORKSPACE_ID\n",
    "- ASANA_TEAM_GID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3fb6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-18 01:28:15,938][WARNING] Failed to load LangChain docs tools: asyncio.run() cannot be called from a running event loop\n",
      "/Users/lokesh/Desktop/seer/Code/seer/shared/tools/mcp_client.py:34: RuntimeWarning: coroutine 'MultiServerMCPClient.get_tools' was never awaited\n",
      "  LANGCHAIN_DOCS_TOOLS = []\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 01:28:16 | eval_agent.graph | \u001b[33mWARNING\u001b[0m | DATABASE_URI not set. Human-in-the-loop interrupts will not work.\n",
      "2025-12-18 01:28:16 | eval_agent.graph | \u001b[33mWARNING\u001b[0m | Set DATABASE_URI environment variable to enable interrupts.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "repo_path = os.path.abspath(\"..\")  # add parent path for imports\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 1. Initialize your checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "from agents.eval_agent.graph import build_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bc23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph()\n",
    "memory = MemorySaver()\n",
    "eval_agent = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf53a92",
   "metadata": {},
   "source": [
    "## Step 1: Agent Expectation alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0790d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_ASANA_BOT_EXPECTATIONS = \"\"\"\n",
    "Evaluate my agent buggy_coder\n",
    "The agent should sync Asana ticket updates when a GitHub PR is merged on it's own. Whenever i merge a PR it should search for realted asana tickets and update/close them.\n",
    "\"\"\"\n",
    "\n",
    "BUGGY_CODER_REPO_SLUG = \"seer-engg/langgraph-skeleton\"\n",
    "\n",
    "USER_ID = \"lokesh@getseer.dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfaece6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_inputs = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"type\": \"human\",\n",
    "            \"content\": GITHUB_ASANA_BOT_EXPECTATIONS\n",
    "        }\n",
    "    ],\n",
    "    \"step\": \"alignment\",\n",
    "    \"input_context\": {\n",
    "        \"integrations\": {\n",
    "            \"github\": {\n",
    "                \"name\": BUGGY_CODER_REPO_SLUG,\n",
    "            }\n",
    "        },\n",
    "        \"user_id\": USER_ID\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64343d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 01:28:32 | eval_agent.plan | \u001b[32mINFO\u001b[0m | Resolved MCP services (requested=['asana', 'github']): ['asana', 'github']\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "results = await eval_agent.ainvoke(compiled_inputs, config=RunnableConfig(configurable={\"thread_id\": thread_id}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45b5898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent name:  buggy_coder\n",
      "mcp services required:  ['asana', 'github']\n",
      "functional requirements:  Monitor the specified GitHub repository and detect when a pull request is merged into the main branch and trigger processing automatically (near‑real‑time).\n",
      "For each merged PR, search the PR title, body, and all associated commits for references to Asana tasks or Asana task URLs and identify all referenced task IDs (supporting multiple tasks).\n",
      "If no Asana tasks are found for a merged PR, record that fact and make no changes to Asana tasks.\n",
      "For every identified Asana task referenced by the PR, add a comment to the Asana task that includes the PR URL, merge commit SHA, merger identity, and a concise summary that the PR was merged and which repository/branch it merged into.\n",
      "If the PR text or commits include an explicit closing intent for a referenced Asana task (for example, common close keywords used immediately with the task reference), mark that Asana task complete/closed; otherwise leave the task open but add the PR comment and a link. \n",
      "Support updating multiple Asana tasks referenced from a single PR in one end‑to‑end run; each referenced task must be handled independently and successfully updated or explicitly reported on failure. \n",
      "Ensure idempotence: repeated processing of the same merged PR must not create duplicate comments on Asana tasks or duplicate state changes (multiple merges or re‑runs should not cause repeated actions).\n",
      "If an update to any Asana task fails (permission error, rate limit, not found, etc.), retry the update with an exponential backoff policy up to a small number of attempts; if still failing, post a clear, machine‑readable summary of the failed updates as a comment on the originating GitHub PR. \n",
      "Provide an auditable summary on the GitHub side for each processed PR: create or update a single PR comment that lists which Asana tasks were detected, which actions were taken (comment added, task closed), which actions failed, and timestamps. \n",
      "Periodically (e.g., a scheduled reconciliation run) re-scan merged PRs within a configurable recent window (e.g., last 30 days) to detect and repair missed or failed Asana updates so eventual consistency is achieved. \n",
      "Respect Asana and GitHub API rate limits and permission boundaries; where rate limits or permission issues occur, the agent must back off and surface clear diagnostics in the PR summary comment. \n",
      "Validate required GitHub and Asana credentials/permissions on startup and produce clear, testable failure messages if required permissions to read PRs or modify Asana tasks are missing. \n",
      "Record sufficient structured logs or metadata (at minimum: PR id/URL, merge SHA, list of Asana task IDs, per‑task action and status, timestamps) to allow deterministic verification of what the agent did for a given merged PR.\n",
      "Make no changes to Asana tasks that are unrelated to the merged PR (no bulk or blanket task edits); only tasks explicitly referenced by the merged PR or its commits may be modified.\n"
     ]
    }
   ],
   "source": [
    "print(\"agent name: \", results.get('context').agent_name)\n",
    "print(\"mcp services required: \", results.get('context').mcp_services)\n",
    "print(\"functional requirements: \", \"\\n\".join(results.get('context').functional_requirements))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8292a",
   "metadata": {},
   "source": [
    "## Step 2: Eval Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5e6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen_inputs = {\n",
    "    \"step\": \"plan\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f51281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 01:29:36 | eval_agent.plan.get_reflections | \u001b[32mINFO\u001b[0m | get_reflections: No Neo4j memory available, returning empty\n",
      "2025-12-18 01:29:36 | eval_agent.plan.generate_evals | \u001b[32mINFO\u001b[0m | Using 'agentic' (structured output) test generation.\n",
      "2025-12-18 01:29:36 | eval_agent.plan.generate_evals | \u001b[32mINFO\u001b[0m | Using reasoning_effort: medium\n",
      "2025-12-18 01:30:56 | eval_agent.plan.generate_evals | \u001b[32mINFO\u001b[0m | plan.generate: produced 1 tests (agent=buggy_coder)\n",
      "2025-12-18 01:31:31 | eval_agent.plan.filter_tools | \u001b[32mINFO\u001b[0m | Selected 47 tools: ['ASANA_ADD_FOLLOWERS_TO_TASK', 'ASANA_ADD_TASK_TO_SECTION', 'ASANA_CREATE_A_TASK', 'ASANA_CREATE_TASK_COMMENT', 'ASANA_DUPLICATE_PROJECT', 'ASANA_DUPLICATE_TASK', 'ASANA_GET_A_TASK', 'ASANA_GET_CURRENT_USER', 'ASANA_GET_MULTIPLE_PROJECTS', 'ASANA_GET_MULTIPLE_TASKS', 'ASANA_GET_PROJECTS_FOR_TEAM', 'ASANA_GET_STORIES_FOR_TASK', 'ASANA_GET_STORY', 'ASANA_GET_TASKS_FROM_A_PROJECT', 'ASANA_GET_TYPEAHEAD_OBJECTS', 'ASANA_GET_USERS_FOR_WORKSPACE', 'ASANA_GET_WORKSPACE', 'ASANA_GET_WORKSPACE_PROJECTS', 'ASANA_SEARCH_TASKS_IN_WORKSPACE', 'ASANA_SUBMIT_PARALLEL_REQUESTS', 'ASANA_UPDATE_A_TASK', 'GITHUB_ACCEPT_A_REPOSITORY_INVITATION', 'GITHUB_ADD_A_REPOSITORY_COLLABORATOR', 'GITHUB_ADD_A_REPOSITORY_TO_AN_APP_INSTALLATION', 'GITHUB_CHECK_IF_A_PULL_REQUEST_HAS_BEEN_MERGED', 'GITHUB_CREATE_A_COMMIT', 'GITHUB_CREATE_A_PULL_REQUEST', 'GITHUB_CREATE_A_REFERENCE', 'GITHUB_CREATE_A_TREE', 'GITHUB_CREATE_OR_UPDATE_FILE_CONTENTS', 'GITHUB_FIND_PULL_REQUESTS', 'GITHUB_GET_A_BLOB', 'GITHUB_GET_A_BRANCH', 'GITHUB_GET_A_COMMIT', 'GITHUB_GET_A_PULL_REQUEST', 'GITHUB_GET_A_REFERENCE', 'GITHUB_GET_A_REPOSITORY', 'GITHUB_GET_A_REPOSITORY_README', 'GITHUB_GET_THE_AUTHENTICATED_USER', 'GITHUB_LIST_BRANCHES', 'GITHUB_LIST_COMMITS', 'GITHUB_LIST_COMMIT_STATUSES_FOR_A_REFERENCE', 'GITHUB_LIST_PULL_REQUESTS', 'GITHUB_LIST_REPOSITORIES_FOR_THE_AUTHENTICATED_USER', 'GITHUB_MERGE_A_PULL_REQUEST', 'GITHUB_REMOVE_STATUS_CHECK_PROTECTION', 'GITHUB_SET_STATUS_CHECK_CONTEXTS']\n"
     ]
    }
   ],
   "source": [
    "planning_results = await eval_agent.ainvoke(eval_gen_inputs, config=RunnableConfig(configurable={\"thread_id\": thread_id}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2b3139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Dataset Example `89de4973-8d8c-4c83-b644-19147bb3958a`\n",
      "\n",
      "- **Status**: `active`\n",
      "\n",
      "#### Input Message\n",
      "\n",
      "```\n",
      "{\n",
      "  \"event\": \"pull_request\",\n",
      "  \"action\": \"closed\",\n",
      "  \"pull_request\": {\n",
      "    \"title\": \"Merge: Fix login bug and Refactor auth module - ASYNCTEST-001\",\n",
      "    \"body\": \"This PR fixes the login bug.\\n\\nFixes Asana task: Fix login bug - ASYNCTEST-001\\nAlso references Asana task: Refactor auth module - ASYNCTEST-001\\n\",\n",
      "    \"merged\": true,\n",
      "    \"merged_by\": { \"login\": \"ci-bot\" },\n",
      "    \"merge_commit_sha\": \"merge-sha-async-001\",\n",
      "    \"html_url\": \"https://github.com/seer-engg/label-edgecase-repo/pull/asynctest-001\"\n",
      "  },\n",
      "  \"repository\": { \"full_name\": \"seer-engg/label-edgecase-repo\" }\n",
      "}\n",
      "```\n",
      "\n",
      "#### Expected Output\n",
      "\n",
      "- **Expected action**: On receiving a PR merged event, find Asana tasks referenced in the PR (by name mentions in the PR body/title), mark any referenced open Asana tasks as completed, and add a comment on each closed-by-this-PR Asana task containing the PR title and a link or the merge commit SHA. Do not reopen or change tasks that were already completed; do not add comments to tasks that were already completed.\n",
      "\n",
      "- **Create test data**:\n",
      "  - **asana**\n",
      "    - In Asana, using the test Asana project with gid <asana_project_gid>, create three tasks with the exact names (use these exact strings):\n",
      "    - - \"Fix login bug - ASYNCTEST-001\" (task A). Set the task's notes/description to: \"test-case: asana_sync_pr_merged_multiple_refs_001 - task A\".\n",
      "    - - \"Update README - ASYNCTEST-001\" (task B). Set the task's notes/description to: \"test-case: asana_sync_pr_merged_multiple_refs_001 - task B\".\n",
      "    - - \"Refactor auth module - ASYNCTEST-001\" (task C). Set the task's notes/description to: \"test-case: asana_sync_pr_merged_multiple_refs_001 - task C\".\n",
      "    - Add an initial comment on each created task with the exact text: \"initial-comment-asana_sync_pr_merged_multiple_refs_001\" (so each task has exactly one comment with that content at setup).\n",
      "    - Mark task B (\"Update README - ASYNCTEST-001\") as completed/closed now (completed=true). Leave task A and task C open (completed=false).\n",
      "    - Do NOT add any other comments or changes. The provisioning system should record the three task names and ensure they reside in <asana_project_gid> so they can be discovered by name later.\n",
      "  - **github**\n",
      "    - In the existing repository seer-engg/label-edgecase-repo, create a branch named: feature/fix-login-async-001 off the default branch, add a trivial commit (e.g., modify README) and push the branch.\n",
      "    - Create a pull request from feature/fix-login-async-001 into the default branch with the exact title: \"Merge: Fix login bug and Refactor auth module - ASYNCTEST-001\" and with the exact body (use the exact lines):\n",
      "    - This PR fixes the login bug.\n",
      "    - \n",
      "    - Fixes Asana task: Fix login bug - ASYNCTEST-001\n",
      "    - Also references Asana task: Refactor auth module - ASYNCTEST-001\n",
      "    - \n",
      "    - Merge the pull request using a regular merge commit (not a squash). The merge commit message should contain: \"Merged for test asana_sync_pr_merged_multiple_refs_001\". Record the PR URL and merge commit sha (provisioner may log them).\n",
      "    - After merging, the PR must be in the merged state (so that a merged=true webhook event would be accurate).\n",
      "\n",
      "- **Assert final state**:\n",
      "  - **asana**\n",
      "    - Locate the three tasks in the Asana project <asana_project_gid> by exact name:\n",
      "    - - Task A: \"Fix login bug - ASYNCTEST-001\"\n",
      "    - - Task B: \"Update README - ASYNCTEST-001\"\n",
      "    - - Task C: \"Refactor auth module - ASYNCTEST-001\"\n",
      "    - For Task A (Fix login bug - ASYNCTEST-001):\n",
      "    -  - Verify the task's completed field is true (the agent should have marked it completed).\n",
      "    -  - Verify the latest (most recent) story/comment on the task is NOT the initial comment text; the newest comment must contain both the PR title string \"Merge: Fix login bug and Refactor auth module - ASYNCTEST-001\" and a reference to the GitHub PR (either the PR URL or the merge commit sha \"merge-sha-async-001\"). The new comment must explicitly mention the PR (e.g., contain the repo name \"seer-engg/label-edgecase-repo\" or the html_url string supplied in the input message).\n",
      "    - For Task C (Refactor auth module - ASYNCTEST-001):\n",
      "    -  - Verify the task's completed field is true (the agent should have marked it completed).\n",
      "    -  - Verify the latest story/comment on the task is NOT the initial comment text; the newest comment must contain the PR title string \"Merge: Fix login bug and Refactor auth module - ASYNCTEST-001\" and a reference to the GitHub PR (PR URL or merge commit sha \"merge-sha-async-001\").\n",
      "    - For Task B (Update README - ASYNCTEST-001):\n",
      "    -  - Verify the task remains completed (completed=true).\n",
      "    -  - Verify the latest story/comment on the task is exactly the initial comment text \"initial-comment-asana_sync_pr_merged_multiple_refs_001\" (i.e., no new comment was added by the agent).\n",
      "    - Notes for assertion: match strings exactly where specified. All task lookups must be by exact name within <asana_project_gid>. If any of the above conditions fail, the agent did not behave as expected.\n",
      "  - **github**\n",
      "    - Verify the PR with title \"Merge: Fix login bug and Refactor auth module - ASYNCTEST-001\" exists in seer-engg/label-edgecase-repo and is in merged state.\n",
      "    - Verify the merge commit sha exists in the repository and matches the sha used in the comment checks (merge-sha-async-001 recorded in create_test_data). This is to confirm the PR merged event is consistent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in planning_results.get('dataset_examples'):\n",
    "    print(example.to_markdown())\n",
    "## Step 2: Test Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac736e",
   "metadata": {},
   "source": [
    "## Step 3: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953be370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 01:31:31 | eval_agent.run | \u001b[32mINFO\u001b[0m | run.prepare: dataset=seer_eval_20251218-0131 experiment=seer-eval-local-20251218-013131\n",
      "2025-12-18 01:31:31 | eval_agent.plan | \u001b[32mINFO\u001b[0m | plan.provision: provisioning sandbox (repo=https://github.com/seer-engg/langgraph-skeleton branch=main)\n",
      "2025-12-18 01:31:31 | sandbox.initialize | \u001b[32mINFO\u001b[0m | Creating E2B sandbox for codex...\n",
      "2025-12-18 01:31:33 | sandbox.initialize | \u001b[32mINFO\u001b[0m | Sandbox created: itro5x8j6phhprsekr3er\n",
      "2025-12-18 01:31:33 | sandbox.initialize | \u001b[32mINFO\u001b[0m | Cloning/updating repository inside sandbox (shell)...\n",
      "2025-12-18 01:32:27 | sandbox.initialize | \u001b[32mINFO\u001b[0m | Setup project: Obtaining file:///home/user/langgraph-skeleton\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pydantic>=2.12.4 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pydantic>=2.12.4 from https://files.pythonhosted.org/packages/5a/87/b70ad306ebb6f9b585f114d0ac2137d792b48be34d732d60e597c2f8465a/pydantic-2.12.5-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting langchain-core>=1.0.7 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langchain-core>=1.0.7 from https://files.pythonhosted.org/packages/59/97/57497c8b26829e38c8dd4abe972d75e38fc3904324a3042bb01d9e0753b8/langchain_core-1.2.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langgraph>=1.0.3 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph>=1.0.3 from https://files.pythonhosted.org/packages/23/1b/e318ee76e42d28f515d87356ac5bd7a7acc8bad3b8f54ee377bef62e1cbf/langgraph-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langgraph-cli[inmem]>=0.4.7 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-cli[inmem]>=0.4.7 from https://files.pythonhosted.org/packages/1c/ac/fd0af9c89638e4d99db8d00b6c6fe1a60f27d9d61b0bbe1d4d5300a74b18/langgraph_cli-0.4.11-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_cli-0.4.11-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langchain-openai>=0.0.5 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langchain-openai>=0.0.5 from https://files.pythonhosted.org/packages/e8/c5/22b690a27ba6b1ca6876270473aab1610cb8767314e5038cb6b826d9b69b/langchain_openai-1.1.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-1.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic-settings>=2.12.0 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pydantic-settings>=2.12.0 from https://files.pythonhosted.org/packages/c1/60/5d4751ba3f4a40a6891f24eec885f51afd78d208498268c734e256fb13c4/pydantic_settings-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting composio>=0.1.0 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for composio>=0.1.0 from https://files.pythonhosted.org/packages/83/61/aa64f9c7fbc0b6765e605229eb88af4581b3317979fb13a63320b0d7377a/composio-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading composio-0.10.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting composio-langchain>=0.1.0 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for composio-langchain>=0.1.0 from https://files.pythonhosted.org/packages/e2/ac/e603fa0d1de0807e26e3f7c3f78be9ff314d8e8f6b1a9441d7432390dcae/composio_langchain-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading composio_langchain-0.10.1-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting langgraph-api>=0.5.23 (from langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-api>=0.5.23 from https://files.pythonhosted.org/packages/92/7e/63e9b6589621489c4c3effc18a73b9ad2db95749893d64799f65d0545007/langgraph_api-0.6.5-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_api-0.6.5-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pysher>=1.0.8 (from composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Downloading Pysher-1.0.8.tar.gz (9.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting composio-client>=1.20.0 (from composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for composio-client>=1.20.0 from https://files.pythonhosted.org/packages/62/63/11d62ccb02cb4217a9c886a8dc858bfb4fbbf5678bde532eee2081de9d95/composio_client-1.20.0-py3-none-any.whl.metadata\n",
      "  Downloading composio_client-1.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for typing-extensions>=4.0.0 from https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting openai (from composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/bb/d5/eb52edff49d3d5ea116e225538c118699ddeb7c29fa17ec28af14bc10033/openai-2.13.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-2.13.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting langchain<2.0.0,>=1.1.0 (from composio-langchain>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langchain<2.0.0,>=1.1.0 from https://files.pythonhosted.org/packages/23/00/4e3fa0d90f5a5c376ccb8ca983d0f0f7287783dfac48702e18f01d24673b/langchain-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for jsonpatch<2.0.0,>=1.33.0 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langsmith<1.0.0,>=0.3.45 from https://files.pythonhosted.org/packages/ee/8a/d9bc95607846bc82fbe0b98d2592ffb5e036c97a362735ae926e3d519df7/langsmith-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.5.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for packaging<26.0.0,>=23.2.0 from https://files.pythonhosted.org/packages/20/12/38679034af332785aac8774540895e234f4d07f7545804097de4b666afd8/packaging-25.0-py3-none-any.whl.metadata\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pyyaml<7.0.0,>=5.3.0 from https://files.pythonhosted.org/packages/71/60/917329f640924b18ff085ab889a11c763e0b573da888e8404ff486657602/pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for tenacity!=8.4.0,<10.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for uuid-utils<1.0,>=0.12.0 from https://files.pythonhosted.org/packages/5a/7a/dbd5e49c91d6c86dba57158bbfa0e559e1ddf377bb46dcfd58aea4f0d567/uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai>=0.0.5->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for tiktoken<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/6a/d0/3d9275198e067f8b65076a68894bb52fd253875f3644f0a321a720277b8a/tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph>=1.0.3->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-checkpoint<4.0.0,>=2.1.0 from https://files.pythonhosted.org/packages/48/e3/616e3a7ff737d98c1bbb5700dd62278914e2a9ded09a79a1fa93cf24ce12/langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph>=1.0.3->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-prebuilt<1.1.0,>=1.0.2 from https://files.pythonhosted.org/packages/87/5e/aeba4a5b39fe6e874e0dd003a82da71c7153e671312671a8dacc5cb7c1af/langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph>=1.0.3->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-sdk<0.4.0,>=0.3.0 from https://files.pythonhosted.org/packages/69/48/ee4d7afb3c3d38bd2ebe51a4d37f1ed7f1058dd242f35994b562203067aa/langgraph_sdk-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_sdk-0.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph>=1.0.3->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for xxhash>=3.5.0 from https://files.pythonhosted.org/packages/a5/86/cf2c0321dc3940a7aa73076f4fd677a0fb3e405cb297ead7d864fd90847e/xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for cloudpickle>=3.0.0 from https://files.pythonhosted.org/packages/88/39/799be3f2f0f38cc727ee3b4f1445fe6d5e4133064ec2e4115069418a5bb6/cloudpickle-3.1.2-py3-none-any.whl.metadata\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cryptography<47.0,>=42.0.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for cryptography<47.0,>=42.0.0 from https://files.pythonhosted.org/packages/8f/29/798fc4ec461a1c9e9f735f2fc58741b0daae30688f41b2497dcbc9ed1355/cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting grpcio-tools==1.75.1 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for grpcio-tools==1.75.1 from https://files.pythonhosted.org/packages/a9/cd/d2a3583a5b1d71da88f7998f20fb5a0b6fe5bb96bb916a610c29269063b6/grpcio_tools-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading grpcio_tools-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.75.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for grpcio<2.0.0,>=1.75.0 from https://files.pythonhosted.org/packages/68/86/093c46e9546073cefa789bd76d44c5cb2abc824ca62af0c18be590ff13ba/grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting httpx>=0.25.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for httpx>=0.25.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jsonschema-rs<0.30,>=0.20.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for jsonschema-rs<0.30,>=0.20.0 from https://files.pythonhosted.org/packages/1f/78/b9b8934e4db4f43f61e65c5f285432c2d07cb1935ad9df88d5080a4a311b/jsonschema_rs-0.29.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jsonschema_rs-0.29.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting langgraph-runtime-inmem<0.21.0,>=0.20.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for langgraph-runtime-inmem<0.21.0,>=0.20.0 from https://files.pythonhosted.org/packages/4c/9c/b3883f862c46379bdd5fe4bd1eb8dce6c3897d7ec2d226b019e0866fad47/langgraph_runtime_inmem-0.20.1-py3-none-any.whl.metadata\n",
      "  Downloading langgraph_runtime_inmem-0.20.1-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting opentelemetry-api>=1.37.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.37.0 from https://files.pythonhosted.org/packages/cf/df/d3f1ddf4bb4cb50ed9b1139cc7b1c54c34a1e7ce8fd1b9a37c0d1551a6bd/opentelemetry_api-1.39.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.37.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-http>=1.37.0 from https://files.pythonhosted.org/packages/95/f1/b27d3e2e003cd9a3592c43d099d2ed8d0a947c15281bf8463a256db0b46c/opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.37.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-sdk>=1.37.0 from https://files.pythonhosted.org/packages/7c/98/e91cf858f203d86f4eccdf763dcf01cf03f1dae80c3750f7e635bfa206b6/opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting orjson>=3.9.7 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for orjson>=3.9.7 from https://files.pythonhosted.org/packages/a7/34/8acb12ff0299385c8bbcbb19fbe40030f23f15a6de57a9c587ebf71483fb/orjson-3.11.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading orjson-3.11.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.6/41.6 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting protobuf<7.0.0,>=6.32.1 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for protobuf<7.0.0,>=6.32.1 from https://files.pythonhosted.org/packages/56/13/333b8f421738f149d4fe5e49553bc2a2ab75235486259f689b4b91f96cec/protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pyjwt>=2.9.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pyjwt>=2.9.0 from https://files.pythonhosted.org/packages/61/ad/689f02752eeec26aed679477e80e632ef1b682313be70793d798c1d5fc8f/PyJWT-2.10.1-py3-none-any.whl.metadata\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting sse-starlette<2.2.0,>=2.1.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for sse-starlette<2.2.0,>=2.1.0 from https://files.pythonhosted.org/packages/52/aa/36b271bc4fa1d2796311ee7c7283a3a1c348bad426d37293609ca4300eef/sse_starlette-2.1.3-py3-none-any.whl.metadata\n",
      "  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting starlette>=0.38.6 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for starlette>=0.38.6 from https://files.pythonhosted.org/packages/d9/52/1064f510b141bd54025f9b55105e26d1fa970b9be67ad766380a3c9b74b0/starlette-0.50.0-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting structlog<26,>=24.1.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for structlog<26,>=24.1.0 from https://files.pythonhosted.org/packages/a8/45/a132b9074aa18e799b891b91ad72133c98d8042c70f6240e4c5f9dabee2f/structlog-25.5.0-py3-none-any.whl.metadata\n",
      "  Downloading structlog-25.5.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting truststore>=0.1 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for truststore>=0.1 from https://files.pythonhosted.org/packages/19/97/56608b2249fe206a67cd573bc93cd9896e1efb9e98bce9c163bcdc704b88/truststore-0.10.4-py3-none-any.whl.metadata\n",
      "  Downloading truststore-0.10.4-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting uvicorn>=0.26.0 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for uvicorn>=0.26.0 from https://files.pythonhosted.org/packages/ee/d9/d88e73ca598f4f6ff671fb5fde8a32925c2e08a637303a1d12883c7305fa/uvicorn-0.38.0-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting watchfiles>=0.13 (from langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/af/b9/a419292f05e302dea372fa7e6fda5178a92998411f8581b9830d28fb9edb/watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from grpcio-tools==1.75.1->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0) (65.5.1)\n",
      "Collecting click>=8.1.7 (from langgraph-cli[inmem]>=0.4.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for click>=8.1.7 from https://files.pythonhosted.org/packages/98/78/01c019cdb5d6498122777c1a43056ebb3ebfeef2076d9d026bfe15583b2b/click-8.3.1-py3-none-any.whl.metadata\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.8.0 (from langgraph-cli[inmem]>=0.4.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for python-dotenv>=0.8.0 from https://files.pythonhosted.org/packages/14/1b/a298b06749107c305e1fe0f814c6c74aea7b2f1e10989cb30f544a1b3253/python_dotenv-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.12.4->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.12.4->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pydantic-core==2.41.5 from https://files.pythonhosted.org/packages/c8/be/8fed28dd0a180dca19e72c233cbf58efa36df055e5b9d90d64fd1740b828/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.12.4->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for typing-inspection>=0.4.2 from https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from composio-client>=1.20.0->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/7f/9c/36c5c37947ebfb8c7f22e0eb6e4d188ee2d53aa3880f3f2744fb894f0cb1/anyio-4.12.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from composio-client>=1.20.0->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from composio-client>=1.20.0->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography<47.0,>=42.0.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for cffi>=2.0.0 from https://files.pythonhosted.org/packages/d7/91/500d892b2bf36529a75b77958edfcd5ad8e2ce4064ce2ecfeab2125d72d1/cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting certifi (from httpx>=0.25.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/70/7d/9bc192684cea499815ff478dfcdc13835ddf401365057044fb721ec6bddb/certifi-2025.11.12-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for idna from https://files.pythonhosted.org/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl.metadata\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=1.0.3->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for ormsgpack>=1.12.0 from https://files.pythonhosted.org/packages/2b/9d/9a49a2686f8b7165dcb2342b8554951263c30c0f0825f1fcc2d56e736a6b/ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting blockbuster<2.0.0,>=1.5.24 (from langgraph-runtime-inmem<0.21.0,>=0.20.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for blockbuster<2.0.0,>=1.5.24 from https://files.pythonhosted.org/packages/95/c1/84fc6811122f54b20de2e5afb312ee07a3a47a328755587d1e505475239b/blockbuster-1.5.26-py3-none-any.whl.metadata\n",
      "  Downloading blockbuster-1.5.26-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for requests-toolbelt>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for requests>=2.0.0 from https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for zstandard>=0.23.0 from https://files.pythonhosted.org/packages/bb/1f/e9cfd801a3f9190bf3e759c422bbfd2247db9d7f3d54a56ecde70137791a/zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for jiter<1,>=0.10.0 from https://files.pythonhosted.org/packages/23/7d/38f9cd337575349de16da575ee57ddb2d5a64d425c9367f5ef9e4612e32e/jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting tqdm>4 (from openai->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 15.0 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for importlib-metadata<8.8.0,>=6.0 from https://files.pythonhosted.org/packages/20/b0/36bd937216ec521246249be3bf9855081de4c5e06a0c9b4219dbeda50373/importlib_metadata-8.7.0-py3-none-any.whl.metadata\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/c4/ab/09169d5a4612a5f92490806649ac8d41e3ec9129c636754575b3553f4ea4/googleapis_common_protos-1.72.0-py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-http>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.39.1 from https://files.pythonhosted.org/packages/8c/02/ffc3e143d89a27ac21fd557365b98bd0653b98de8a101151d5805b5d4c33/opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-http>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.39.1 from https://files.pythonhosted.org/packages/51/95/b40c96a7b5203005a0b03d8ce8cd212ff23f1793d5ba289c87a097571b18/opentelemetry_proto-1.39.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.60b1 from https://files.pythonhosted.org/packages/7a/5e/5958555e09635d09b75de3c4f8b9cae7335ca545d77392ffe7331534c402/opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting websocket-client!=0.49 (from pysher>=1.0.8->composio>=0.1.0->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for websocket-client!=0.49 from https://files.pythonhosted.org/packages/34/db/b10e48aa8fff7407e67470363eac595018441cf32d5e1001567a7aeba5d2/websocket_client-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.0.5->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/61/22/b8cb00df7d2b5e0875f60628594d44dba283e951b1ae17c12f99e332cc0a/regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 12.5 MB/s eta 0:00:00\n",
      "Collecting forbiddenfruit>=0.1.4 (from blockbuster<2.0.0,>=1.5.24->langgraph-runtime-inmem<0.21.0,>=0.20.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Downloading forbiddenfruit-0.1.4.tar.gz (43 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 kB 12.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography<47.0,>=42.0.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/a0/e3/59cd50310fc9b59512193629e1984c1f95e5c8ae6e5d8c69532ccc65a7fe/pycparser-2.23-py3-none-any.whl.metadata\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.37.0->langgraph-api>=0.5.23->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for zipp>=3.20 from https://files.pythonhosted.org/packages/2e/54/647ade08bf0db230bfea292f893923872fd20be6ac6f53b2b936ba839d75/zipp-3.23.0-py3-none-any.whl.metadata\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for charset_normalizer<4,>=2 from https://files.pythonhosted.org/packages/6d/fc/de9cce525b2c5b94b47c70a4b4fb19f871b24995c728e957ee68ab1671ea/charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=1.0.7->langgraph-skeleton==0.1.0)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/6d/b9/4095b668ea3678bf6a0af005527f39de12fb026516fb3df17495a733b7f8/urllib3-2.6.2-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading composio-0.10.1-py3-none-any.whl (80 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.7/80.7 kB 21.1 MB/s eta 0:00:00\n",
      "Downloading composio_langchain-0.10.1-py3-none-any.whl (3.4 kB)\n",
      "Downloading langchain_core-1.2.2-py3-none-any.whl (476 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 476.1/476.1 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-1.1.5-py3-none-any.whl (84 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.6/84.6 kB 19.1 MB/s eta 0:00:00\n",
      "Downloading langgraph-1.0.5-py3-none-any.whl (157 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 157.1/157.1 kB 13.1 MB/s eta 0:00:00\n",
      "Downloading langgraph_api-0.6.5-py3-none-any.whl (317 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.0/317.0 kB 16.1 MB/s eta 0:00:00\n",
      "Downloading grpcio_tools-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 463.6/463.6 kB 31.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 37.8 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.9/51.9 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.3/108.3 kB 28.5 MB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading composio_client-1.20.0-py3-none-any.whl (200 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.1/200.1 kB 42.0 MB/s eta 0:00:00\n",
      "Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 52.4 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 62.4 MB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.5/73.5 kB 19.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.8/78.8 kB 21.7 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jsonschema_rs-0.29.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 62.1 MB/s eta 0:00:00\n",
      "Downloading langchain-1.2.0-py3-none-any.whl (102 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.8/102.8 kB 26.4 MB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.2/46.2 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_runtime_inmem-0.20.1-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.0-py3-none-any.whl (66 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.5/66.5 kB 18.1 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.5.0-py3-none-any.whl (273 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 273.7/273.7 kB 44.0 MB/s eta 0:00:00\n",
      "Downloading openai-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 67.0 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 20.3 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 20.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 31.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 44.6 MB/s eta 0:00:00\n",
      "Downloading orjson-3.11.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.8/138.8 kB 32.0 MB/s eta 0:00:00\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.5/66.5 kB 12.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 323.3/323.3 kB 59.6 MB/s eta 0:00:00\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 806.6/806.6 kB 71.8 MB/s eta 0:00:00\n",
      "Downloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 kB 20.6 MB/s eta 0:00:00\n",
      "Downloading structlog-25.5.0-py3-none-any.whl (72 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 19.9 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 59.9 MB/s eta 0:00:00\n",
      "Downloading truststore-0.10.4-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.7/343.7 kB 38.9 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.1/68.1 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 456.1/456.1 kB 44.0 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.9/193.9 kB 41.6 MB/s eta 0:00:00\n",
      "Downloading langgraph_cli-0.4.11-py3-none-any.whl (41 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 113.4/113.4 kB 28.7 MB/s eta 0:00:00\n",
      "Downloading blockbuster-1.5.26-py3-none-any.whl (13 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 215.6/215.6 kB 39.6 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 297.5/297.5 kB 37.9 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.0/71.0 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 364.6/364.6 kB 57.1 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.3/211.3 kB 49.6 MB/s eta 0:00:00\n",
      "Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.4/800.4 kB 79.2 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.7/64.7 kB 19.0 MB/s eta 0:00:00\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.4/159.4 kB 39.1 MB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.6/82.6 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 61.2 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.6/151.6 kB 37.1 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.2/131.2 kB 35.4 MB/s eta 0:00:00\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.1/118.1 kB 32.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: langgraph-skeleton, pysher, forbiddenfruit\n",
      "  Building editable for langgraph-skeleton (pyproject.toml): started\n",
      "  Building editable for langgraph-skeleton (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langgraph-skeleton: filename=langgraph_skeleton-0.1.0-0.editable-py3-none-any.whl size=1497 sha256=3fa5c5575e8147fbb21bcfd7cfa76f64c7c0a59288d21ef20c1353b9b2a18b8b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mcjkoe6j/wheels/59/4c/f0/bf7342250f4c821c9a577e2a83f229eb1d712dec057567f49b\n",
      "  Building wheel for pysher (setup.py): started\n",
      "  Building wheel for pysher (setup.py): finished with status 'done'\n",
      "  Created wheel for pysher: filename=Pysher-1.0.8-py3-none-any.whl size=9888 sha256=107e09bc1ebe976afd0c5292e28f0c73ea825976c88eb882309073dbf74e7cda\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/79/f8/4a/46e34939a44ed8992d6931a3358b547b048aa987c0e7c6d551\n",
      "  Building wheel for forbiddenfruit (setup.py): started\n",
      "  Building wheel for forbiddenfruit (setup.py): finished with status 'done'\n",
      "  Created wheel for forbiddenfruit: filename=forbiddenfruit-0.1.4-py3-none-any.whl size=21791 sha256=edfa0488fae5feba4273b7e8ef51c9239e76ff43c0244730a937d64173bbca49\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/a3/09/38/5a94e2df4ae8f2cfc8053997507ad46b07009af3afc34a9a9c\n",
      "Successfully built langgraph-skeleton pysher forbiddenfruit\n",
      "Installing collected packages: forbiddenfruit, zstandard, zipp, xxhash, websocket-client, uuid-utils, urllib3, typing-extensions, truststore, tqdm, tenacity, structlog, sniffio, regex, pyyaml, python-dotenv, pyjwt, pycparser, protobuf, packaging, ormsgpack, orjson, jsonschema-rs, jsonpointer, jiter, idna, h11, distro, cloudpickle, click, charset_normalizer, certifi, blockbuster, annotated-types, uvicorn, typing-inspection, requests, pydantic-core, opentelemetry-proto, jsonpatch, importlib-metadata, httpcore, grpcio, googleapis-common-protos, cffi, anyio, watchfiles, tiktoken, starlette, requests-toolbelt, pysher, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpx, grpcio-tools, cryptography, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, openai, langsmith, langgraph-sdk, composio-client, opentelemetry-sdk, langgraph-cli, langchain-core, composio, opentelemetry-exporter-otlp-proto-http, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langgraph-runtime-inmem, langchain, langgraph-api, composio-langchain, langgraph-skeleton\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.0 blockbuster-1.5.26 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 composio-0.10.1 composio-client-1.20.0 composio-langchain-0.10.1 cryptography-46.0.3 distro-1.9.0 forbiddenfruit-0.1.4 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-tools-1.75.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 importlib-metadata-8.7.0 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-rs-0.29.1 langchain-1.2.0 langchain-core-1.2.2 langchain-openai-1.1.5 langgraph-1.0.5 langgraph-api-0.6.5 langgraph-checkpoint-3.0.1 langgraph-cli-0.4.11 langgraph-prebuilt-1.0.5 langgraph-runtime-inmem-0.20.1 langgraph-sdk-0.3.0 langgraph-skeleton-0.1.0 langsmith-0.5.0 openai-2.13.0 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-http-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 orjson-3.11.5 ormsgpack-1.12.1 packaging-25.0 protobuf-6.33.2 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 pyjwt-2.10.1 pysher-1.0.8 python-dotenv-1.2.1 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 sse-starlette-2.1.3 starlette-0.50.0 structlog-25.5.0 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 truststore-0.10.4 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.2 uuid-utils-0.12.0 uvicorn-0.38.0 watchfiles-1.1.1 websocket-client-1.9.0 xxhash-3.6.0 zipp-3.23.0 zstandard-0.25.0\n",
      "\n",
      "2025-12-18 01:32:29 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDERR #1] Length: 423\n",
      "2025-12-18 01:32:29 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: 'INFO:langgraph_api.cli:\\n\\n        Welcome to\\n\\n╦  ┌─┐┌┐┌┌─┐╔═╗┬─┐┌─┐┌─┐┬ ┬\\n║  ├─┤││││ ┬║ ╦├┬┘├─┤├─┘├─┤\\n╩═╝┴ ┴┘└┘└─┘╚═╝┴└─┴ ┴┴  ┴ ┴\\n\\n- 🚀 API: \\x1b[36mhttp://0.0.0.0:2024\\x1b[0m\\n- 🎨 Studio UI: \\x1b[36mhttps://smit'\n",
      "2025-12-18 01:32:29 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Buffer size: 423 chars\n",
      "2025-12-18 01:32:29 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   No patterns matched yet (checked 1 success + 5 failure patterns)\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #1] Length: 268\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.415621Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mUsing langgraph_runtime_inmem \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_runtime\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mlanggraph_api_'\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #2] Length: 280\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.429992Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mUsing auth of type=noop       \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_api.auth.middleware\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mla'\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #3] Length: 421\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.434472Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mStarting In-Memory runtime with langgraph-api=0.6.5 and in-memory runtime=0.20.1\\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_runtime_inmem.lifespan\\x1b[0m'\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #4] Length: 266\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.475243Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1m1 change detected             \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mwatchfiles.main\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mlanggraph_api_ve'\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #5] Length: 366\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.519826Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mStarting thread TTL sweeper with interval 5 minutes\\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_api.thread_ttl\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal'\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #6] Length: 266\n",
      "2025-12-18 01:32:30 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:30.826402Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1m1 change detected             \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mwatchfiles.main\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mlanggraph_api_ve'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #7] Length: 470\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:31.593419Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mImporting graph with id agent \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_api.timing\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36melapsed_sec'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #8] Length: 279\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:31.701033Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mStarting 1 background workers \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_runtime_inmem.queue\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mla'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #9] Length: 360\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:31.702281Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mWorker stats                  \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_runtime_inmem.queue\\x1b[0m]\\x1b[0m \\x1b[36mactive\\x1b[0m=\\x1b[35m0\\x1b[0m \\x1b[36mapi_variant\\x1b[0m'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #10] Length: 1099\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:31.714235Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mServer started in 2.94s       \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mbrowser_opener\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mlanggraph_api_ver'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDERR #2] Length: 129\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: 'Server started in 2.94s\\n🎨 Opening Studio in your browser...\\nURL: https://smith.langchain.com/studio/?baseUrl=http://0.0.0.0:2024\\n'\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Buffer size: 4627 chars\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | ✓ SUCCESS PATTERN FOUND IN STDERR!\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | Success pattern detected, verifying with probes...\n",
      "2025-12-18 01:32:31 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | Probing from inside sandbox: http://0.0.0.0:2024/docs\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   stdout: <!doctype html>\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Scalar API Reference</title>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta\n",
      "      name=\"viewport\"\n",
      "      content=\"width=device-width, initial-scale=1\" />\n",
      "  </head>\n",
      "  \n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   stderr: None\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   exit_code: 0\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Result: ✓ SUCCESS\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | Internal probe passed, checking external connectivity...\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | Probing from outside: https://2024-itro5x8j6phhprsekr3er.e2b.app/docs\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | [STDOUT #11] Length: 449\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Content: '\\x1b[2m2025-12-17T20:02:32.204778Z\\x1b[0m [\\x1b[32m\\x1b[1minfo     \\x1b[0m] \\x1b[1mQueue stats                   \\x1b[0m [\\x1b[0m\\x1b[1m\\x1b[34mlanggraph_runtime_inmem.queue\\x1b[0m]\\x1b[0m \\x1b[36mapi_variant\\x1b[0m=\\x1b[35mlocal_dev\\x1b[0m \\x1b[36mla'\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   status_code: 200\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   response length: 534 chars\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m |   Result: ✓ SUCCESS\n",
      "2025-12-18 01:32:32 | sandbox.deploy_server | \u001b[32mINFO\u001b[0m | ✓ Server is ready and accessible from outside!\n",
      "2025-12-18 01:32:32 | eval_agent.plan | \u001b[32mINFO\u001b[0m | plan.provision: sandbox ready at https://2024-itro5x8j6phhprsekr3er.e2b.app\n",
      "2025-12-18 01:32:32 | eval_agent.execute.seed_mcp_resources | \u001b[32mINFO\u001b[0m | Seeding MCP resources for asana with seed amusing-bulldog\n",
      "2025-12-18 01:32:32 | shared.integrations.providers.asana | \u001b[32mINFO\u001b[0m | Provisioning ASANA resources with seed amusing-bulldog\n",
      "2025-12-18 01:32:32 | shared.integrations.providers.asana | \u001b[32mINFO\u001b[0m | Attempting to create new Asana project...\n",
      "2025-12-18 01:32:35 | shared.integrations.providers.asana | \u001b[32mINFO\u001b[0m | Project GID: 1212505002915133\n",
      "2025-12-18 01:32:35 | eval_agent.execute.seed_mcp_resources | \u001b[32mINFO\u001b[0m | Seeded MCP resources for asana with seed amusing-bulldog\n",
      "2025-12-18 01:32:35 | eval_agent.execute.seed_mcp_resources | \u001b[32mINFO\u001b[0m | Seeding MCP resources for github with seed amusing-bulldog\n",
      "2025-12-18 01:32:35 | shared.integrations.providers.github | \u001b[33mWARNING\u001b[0m | Provisioning GitHub resources is not implemented\n",
      "2025-12-18 01:32:35 | eval_agent.execute.seed_mcp_resources | \u001b[32mINFO\u001b[0m | Seeded MCP resources for github with seed amusing-bulldog\n",
      "2025-12-18 01:35:41 | eval_agent.execute.verify_provisioning | \u001b[32mINFO\u001b[0m | Provisioning verification: ✅ SUCCEEDED\n",
      "2025-12-18 01:35:41 | eval_agent.execute.invoke | \u001b[32mINFO\u001b[0m | 🎯 Invoking target agent: context_level=0, base_msg_len=576, formatted_msg_len=576, msg_preview={\n",
      "  \"event\": \"pull_request\",\n",
      "  \"action\": \"closed\",\n",
      "  \"pull_request\": {\n",
      "    \"title\": \"Merge: Fix logi...\n",
      "2025-12-18 01:35:41 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Invoking target agent 'buggy_coder' with message: {\n",
      "  \"event\": \"pull_request\",\n",
      "  \"action\": \"closed\",\n",
      "  \"pull_request\": {\n",
      "    \"title\": \"Merge: Fix logi...\n",
      "2025-12-18 01:35:41 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Connecting to sandbox itro5x8j6phhprsekr3er...\n",
      "2025-12-18 01:35:42 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Agent deployment URL: https://2024-itro5x8j6phhprsekr3er.e2b.app\n",
      "2025-12-18 01:35:42 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Creating new thread for agent invocation...\n",
      "2025-12-18 01:35:42 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Thread created: 5dc9aed0-892e-4839-b1fb-60011fbc27dc\n",
      "2025-12-18 01:35:42 | test_runner.agent_invoker | \u001b[32mINFO\u001b[0m | Sending input_message to agent: '{\n",
      "  \"event\": \"pull_request\",\n",
      "  \"action\": \"closed\",\n",
      "  \"pull_request\": {\n",
      "    \"title\": \"Merge: Fix logi...'\n",
      "2025-12-18 01:35:43 | test_runner.agent_invoker | \u001b[31mERROR\u001b[0m | Failed to invoke agent: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lokesh/Desktop/seer/Code/seer/shared/test_runner/agent_invoker.py\", line 124, in invoke_target_agent\n",
      "    result = await asyncio.wait_for(invoke_task, timeout=timeout_seconds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 507, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/lokesh/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/remote.py\", line 945, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/lokesh/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/remote.py\", line 730, in stream\n",
      "    for chunk in sync_client.runs.stream(\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        thread_id=thread_id,\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<13 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/lokesh/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph_sdk/client.py\", line 3892, in stream\n",
      "    _raise_for_status_typed(res)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/lokesh/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph_sdk/errors.py\", line 231, in _raise_for_status_typed\n",
      "    raise err\n",
      "langgraph_sdk.errors.UnprocessableEntityError\n",
      "2025-12-18 01:35:43 | eval_agent.execute.invoke | \u001b[31mERROR\u001b[0m | Error invoking target agent: Agent invocation failed after 1.50s: . Check that the agent is properly deployed and accessible at the sandbox URL.\n",
      "2025-12-18 01:35:47 | eval_agent.execute.clean_mcp_resources | \u001b[32mINFO\u001b[0m | Cleaning up MCP resources for asana with seed amusing-bulldog\n",
      "2025-12-18 01:35:47 | shared.integrations.providers.asana | \u001b[32mINFO\u001b[0m | Cleaning up ASANA resources with project id \n",
      "2025-12-18 01:35:49 | eval_agent.execute.clean_mcp_resources | \u001b[32mINFO\u001b[0m | Cleaned up MCP resources for asana with seed amusing-bulldog\n",
      "2025-12-18 01:35:49 | eval_agent.execute.clean_mcp_resources | \u001b[32mINFO\u001b[0m | Cleaning up MCP resources for github with seed amusing-bulldog\n",
      "2025-12-18 01:35:49 | shared.integrations.providers.github | \u001b[33mWARNING\u001b[0m | Cleaning up GitHub resources is not implemented\n",
      "2025-12-18 01:35:49 | eval_agent.execute.clean_mcp_resources | \u001b[32mINFO\u001b[0m | Cleaned up MCP resources for github with seed amusing-bulldog\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LANGFUSE_SECRET_KEY environment variable is required for experiment upload.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m testing_inputs = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtesting\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m testing_results = \u001b[38;5;28;01mawait\u001b[39;00m eval_agent.ainvoke(testing_inputs, config=RunnableConfig(configurable={\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: thread_id}))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/main.py:3158\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3155\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3156\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3158\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3159\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3160\u001b[39m     config,\n\u001b[32m   3161\u001b[39m     context=context,\n\u001b[32m   3162\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3165\u001b[39m     print_mode=print_mode,\n\u001b[32m   3166\u001b[39m     output_keys=output_keys,\n\u001b[32m   3167\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3168\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3169\u001b[39m     durability=durability,\n\u001b[32m   3170\u001b[39m     **kwargs,\n\u001b[32m   3171\u001b[39m ):\n\u001b[32m   3172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3173\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/main.py:2971\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2970\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2972\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2973\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2974\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2975\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2976\u001b[39m ):\n\u001b[32m   2977\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2979\u001b[39m         stream_mode,\n\u001b[32m   2980\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2983\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2984\u001b[39m     ):\n\u001b[32m   2985\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/main.py:3158\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3155\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3156\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3158\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3159\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3160\u001b[39m     config,\n\u001b[32m   3161\u001b[39m     context=context,\n\u001b[32m   3162\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3165\u001b[39m     print_mode=print_mode,\n\u001b[32m   3166\u001b[39m     output_keys=output_keys,\n\u001b[32m   3167\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3168\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3169\u001b[39m     durability=durability,\n\u001b[32m   3170\u001b[39m     **kwargs,\n\u001b[32m   3171\u001b[39m ):\n\u001b[32m   3172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3173\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/main.py:2971\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2970\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2972\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2973\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2974\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2975\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2976\u001b[39m ):\n\u001b[32m   2977\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2979\u001b[39m         stream_mode,\n\u001b[32m   2980\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2983\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2984\u001b[39m     ):\n\u001b[32m   2985\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/env/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seer/Code/seer/agents/eval_agent/nodes/testing/run.py:58\u001b[39m, in \u001b[36mupload_run_results\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Initialize Langfuse client\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.langfuse_secret_key:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLANGFUSE_SECRET_KEY environment variable is required for experiment upload.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Initialize Langfuse client with config\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangfuse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Langfuse\n",
      "\u001b[31mValueError\u001b[39m: LANGFUSE_SECRET_KEY environment variable is required for experiment upload.",
      "During task with name 'upload_run_results' and id '8e2260ed-0770-60eb-aca7-68a707fd3723'",
      "During task with name 'testing' and id '8c59dfab-de39-ee0b-5e1c-296df2d39db7'"
     ]
    }
   ],
   "source": [
    "testing_inputs = {\n",
    "    \"step\": \"testing\",\n",
    "}\n",
    "testing_results = await eval_agent.ainvoke(testing_inputs, config=RunnableConfig(configurable={\"thread_id\": thread_id}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
