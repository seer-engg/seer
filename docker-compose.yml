services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow_local:/mlflow
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --allowed-hosts "mlflow:5000,localhost:5000,127.0.0.1:5000"
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root file:/mlflow/artifacts
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://127.0.0.1:5000')"]
      interval: 10s
      timeout: 5s
      retries: 10

  langgraph-server:
    build:
      context: .
      dockerfile: Dockerfile          # <-- your existing root Dockerfile
    container_name: langgraph-server
    ports:
      - "8000:8000"                   # change if your server uses another port
    depends_on:
      mlflow:
        condition: service_healthy
    env_file:
      - .env
    environment:
      MLFLOW_TRACKING_URI: "http://mlflow:5000"
      MLFLOW_EXPERIMENT_NAME: "langgraph-local"
